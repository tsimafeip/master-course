{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №5 по курсу \"Машинное обучение\"\n",
    "\n",
    "Прокопенко Тимофей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1.\n",
    "**Решение:**<br>\n",
    "В алгоритме k-fold параметр k влияет на часть выборки, используемую для валидации (1/k). \n",
    "\n",
    "Его нужно выбирать большим, если размер выборки невелик. В таком случае будет хорошее качество тренировки, валидация показывает нестабильные результаты, но усреднение даст приемлемое значение, которое можно принять в рассмотрение.\n",
    "\n",
    "K выбирают маленьким, если в выборке много объектов. Тогда получается тренировка на репрезентативном количестве данных и хорошая валидация. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2.\n",
    "**Решение:**<br>\n",
    "Тренировочной и валидационной выборки не хватает для решения практических задач, так как существует риск переобучения. Тестовые данные никогда не доступны для во время обучения, следовательно, модель не может приспособиться к решению задачи на конкретных экземплярах.\n",
    "\n",
    "Также на валидационной выборке мы выбираем лучшую из обученных конкретных алгоритмом моделей, а на тестовой проверяем, насколько эта лучшая модель корректна для решения задачи в общем случае."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 3.\n",
    "**Решение:**<br>\n",
    "Недостатки:\n",
    "1. Число всевозможных разбиений выборки на две части очень велико, таким образом алгоритм \"leave-all-out\" будет работать очень долго. \n",
    "2. Все возможные разбиения на две выборки включают в себя очень маленькие тренировочные и валидационные наборы данных, то есть очень неадекватные оценки будут включены в итоговую оценку наравне с корректными значениями.\n",
    "\n",
    "Преимущества:\n",
    "1. Не зависит от k, таким образом мы каждый раз получаем оценки зависящие только от качества алгоритма обучения модели, а не от параметра.\n",
    "2. Различный размер тренировочных выборок позволяет проверить склонность модели к переобучению."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
