{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №3 по курсу \"Машинное обучение\"\n",
    "\n",
    "Прокопенко Тимофей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1.\n",
    "**Решение:**<br>\n",
    "Необходимо найти VCdim(H), где H - семейство линейных бинарных классификаторов в d-мерном пространстве.\n",
    "Рассмотрим линейные бинарные классификаторы вида $h(x)=sign(w^Tx), w \\in R^d$. <br>\n",
    "\n",
    "а) Предположим, что VCdim(H)=d. Для этого нужно найти С размера d, которое раскрашивается с помощью H.<br>\n",
    "Возьмем в качестве С базис d-мерного пространства, то есть вектора $x_i$ вида (0, 0, ..., $1_i$, ...0), где $i=\\overline{1,d}$. <br>\n",
    "$y=(y_1, y_2, ....., y_n)$, $y_i \\in ${-1,1}$ i=\\overline{1,d}$ - значение произвольной функции из $H_C$.<br>\n",
    "В качестве гипотез $H_C$ выберем $h(x_j)=sign(\\sum\\limits_{i=1}^d y_i x_i^T x_j)$, где $y_i \\in $ {-1,1}$, w=\\sum\\limits_{i=1}^d y_i x_i \\in R^d,$ $x_j, x_i \\in C$. <br>\n",
    "Так как $x_i^T*x_j = 0$ при $i, j = \\overline{1,d}, i \\ne j$, а $x_i^T*x_i = 1$, то $h(x_i)=sign(y_i)$. Таким образом, H разукрашивает d-мерное пространство.\n",
    "\n",
    "б) Допустим, что с помощью H можно раскрасить (d+1)-мерное пространство. Но в таком пространстве найдется вектор, который будет являться линейной комбинацией остальных d векторов и, следовательно, его классификация будет предопределена. \n",
    "Таким образом, пространство размерности d+1 не может быть раскрашено Н, и VCdim(H)=d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 3.\n",
    "**Решение:**<br>\n",
    "Повторим начальные рассуждения из первой задачи.\n",
    "Предположим, что VCdim(H)=n. Для этого нужно найти С размера n, которое раскрашивается с помощью H.<br>\n",
    "Возьмем в качестве С базис n-мерного пространства, то есть вектора $x_i$ вида (0, 0, ..., $1_i$, ...0), где $i=\\overline{1,n}$. <br>\n",
    "Пусть $y=(y_1, y_2, ....., y_n)$, $y_i \\in ${0,1}$ i=\\overline{1,d}$ - значение произвольной функции из $H_C$.\n",
    "Выберем такое множество $I_C =${$i| y_i=1$}. Тогда, учитывая характер ранее выбранного множества С, получим\n",
    "\n",
    "$$h_{I_C}(x_i) = \\begin{cases} 1, & \\mbox{если i $ \\in I_C$} \\\\ 0, & \\mbox{иначе} \\end{cases}$$\n",
    "\n",
    "Таким образом, H раскрашивает множество размера n.\n",
    "\n",
    "Множество размера n+1 не может быть раскрашено, т.к. $VCdim(H) \\leq ln(|H|)$, |H|=$2^n$ => $VCdim(H) \\leq n$. \n",
    "Значит $VCdim(H)=n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 4.\n",
    "**Решение:**<br>\n",
    "1. ERM-алгоритм над конечным классом H - PAC-learnable в случае гипотезы реализуемости рассматривает только те D, для которых гипотеза реализуемости выполняется. В то время как NFL theorem рассматривает все D.\n",
    "2. ERM-алгоритм над конечным классом H - agnostic PAC-learnable говорит, что для выбранной гипотезы h $L_D(h)$ отклоняется от $L_D(h')$ (h' - лучшая возможная гипотеза) не больше, чем на $\\varepsilon$ c вероятностью 1-$\\delta$ ($\\varepsilon, \\delta \\in (0,1)$). NFL theorem этому не противоречит, там говорится, что для нашей гипотезы h найдется D, что $L_D(h) \\geq 1/8$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
