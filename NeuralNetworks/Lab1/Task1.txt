Задание

Натренируйте 30 эпох сверточную нейронную сеть LeNet-5 на датасете конкурса https://www.kaggle.com/c/Kannada-MNIST/overview с использованием стохастического градиентного спуска и размером батча 16. Какая точность на валидации?  [2 балл]
Попробуйте поменять размер батча. Что изменилось? Объясните.  [1 балл]
Реализуйте свою собственную нейронную сеть, которая как вам кажется, может занять высокое место в конкурсе. Загрузите решение на Kaggle.  Отразите в отчете точность вашего прогноза. Вам будет начислено 50 * ReLU(public_score - 0.95) + 50 * ReLU(private_score - 0.95) баллов [до 5 баллов].
Ответьте на вопросы в отчете:
Какие функции активации вы использовали и почему? [1 балл]
Полезна ли именно вашей сети ли вам оказалась операция BatchNormalization? Почему? [1 балл]
Переучите вашу самую лучшую (или одну из лучших) архитетектур с обычным SGD оптимизатором, SGD с моментом, RMSProb, Adam. Сохраните CSV лог обучения и валидации. Постройте кривые обучения. Объясните результат. [2 балла]

Tutorials и полезные материалы
Основы Keras: https://www.tensorflow.org/guide/keras/overview (Обратите внимание на возможность Run in Colab)
Основы Keras Functional API: https://www.tensorflow.org/guide/keras/functional (Обратите внимание на на возможность Run in Colab)
Callback-и в Keras: https://keras.io/callbacks/
Пример обучения сверточной нейронной сети с демонстрацией влияния разных методом оптимизации: https://www.kaggle.com/ilyamich/kannada-mnist-choosing-the-right-optimizer 
MNIST State-of-the-art: https://paperswithcode.com/sota/image-classification-on-mnist